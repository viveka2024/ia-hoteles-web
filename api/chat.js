// api/chat.js

import OpenAI from "openai";
import { getLatestOfferText } from "./offersHelper.js";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export default async function handler(req, res) {
  console.log("ğŸ’¡ Request to /api/chat");

  if (req.method !== "POST") {
    return res.status(405).json({ error: "Solo se permiten solicitudes POST" });
  }

  // Validar mensaje
  const { message } = req.body;
  if (!message) {
    return res.status(400).json({ error: "El campo 'message' es requerido" });
  }

  try {
    // â”€â”€â”€ Recuperar texto de la Ãºltima oferta activa â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const ofertaTexto = await getLatestOfferText();

   // â”€â”€â”€ LÃ³gica con OpenAI Threads, inyectando la oferta como mensaje de ASISTENTE â”€
const thread = await openai.beta.threads.create();

// 1) Mensaje de ASISTENTE con la oferta y la instrucciÃ³n de integrarla
await openai.beta.threads.messages.create(thread.id, {
  role: "assistant",
  content: `
ğŸ“¢ *PROMOCIÃ“N ACTUAL* ğŸ“¢
${ofertaTexto}

â†’ A la hora de responder al usuario, integra esta oferta donde sea relevante.
  `.trim()
});

// 2) Mensaje real del cliente
await openai.beta.threads.messages.create(thread.id, {
  role: "user",
  content: message,
});

    // â”€â”€â”€ Ejecutar el run del asistente â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const run = await openai.beta.threads.runs.create(thread.id, {
      assistant_id: process.env.ASSISTANT_ID,
    });

    let status = "queued";
    while (!["completed", "failed", "cancelled"].includes(status)) {
      const runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
      status = runStatus.status;
      if (status !== "completed") {
        await new Promise((r) => setTimeout(r, 1000));
      }
    }
    if (status !== "completed") {
      return res.status(500).json({ error: `EjecuciÃ³n con estado: ${status}` });
    }

    // â”€â”€â”€ Recoger la respuesta del asistente â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const messages = await openai.beta.threads.messages.list(thread.id);
    const assistantMsg = messages.data.find((m) => m.role === "assistant");
    const reply = assistantMsg?.content?.[0]?.text?.value;
    if (!reply) {
      return res.status(500).json({ error: "El asistente no devolviÃ³ una respuesta vÃ¡lida." });
    }
    const finalReply = reply.replace(/ã€\d+:\d+â€ sourceã€‘/g, "").trim();

    // â”€â”€â”€ Devolvemos la respuesta al cliente â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    return res.status(200).json({ reply: finalReply });

  } catch (error) {
    console.error("âŒ Error en /api/chat:", error);
    let errorMsg = "Error inesperado del servidor.";
    if (error.response) {
      try {
        errorMsg = await error.response.text();
      } catch {}
    } else if (error.message) {
      errorMsg = error.message;
    }
    return res.status(500).json({ error: errorMsg });
  }
}


